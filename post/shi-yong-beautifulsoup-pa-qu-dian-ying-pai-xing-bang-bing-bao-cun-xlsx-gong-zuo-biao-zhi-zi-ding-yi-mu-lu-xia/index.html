<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>猫眼Top电影信息获取 | posierd</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://posierd.github.io/favicon.ico?v=1586331971097">
<link rel="stylesheet" href="https://posierd.github.io/styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="😃😃😃
# https://movie.douban.com/top250
# https://movie.douban.com/top250?start=25&amp;filter=
# https://movie.douban.c..." />
    <meta name="keywords" content="Python-Get" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://posierd.github.io">
        <img src="https://posierd.github.io/images/avatar.png?v=1586331971097" class="site-logo">
        <h1 class="site-title">posierd</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      温故而知新
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://posierd.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">猫眼Top电影信息获取</h2>
            <div class="post-date">2020-02-21</div>
            
            <div class="post-content" v-pre>
              <p>😃😃😃</p>
<pre><code class="language-python"># https://movie.douban.com/top250
# https://movie.douban.com/top250?start=25&amp;filter=
# https://movie.douban.com/top250?start=50&amp;filter=
#   用过观察找出 页面 url 的变化规律  每次 start的值 增加25
import requests
from bs4 import BeautifulSoup
import openpyxl   #  第三方库 （用于建立 Excel 表） 通过 pip instal openpyxl  下载安装
list2 = []   # 用于将爬取的信息存入此列表方便存入 Excel 表中
for i in range(1,11):
    #  生成 1,2,3,4,5,6,7,8,9,10,11
    number =  (i-1)*25
    #print(number)
    #   数据请求
    link = 'https://movie.douban.com/top250?start='+str(number)+'&amp;filter='
    #print(i,link)
    headers ={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36',
    }   #  当中为 User-Agent  字段 ，注意为字典格式
    r = requests.get(link,headers=headers)
    #print(r.status_code)   页面状态响应码



    #  数据转换
    soup = BeautifulSoup(r.text,'html.parser')
    #print(soup)



    #  提取数据
    #   找出最小级的父标签(一个数据)
    nu = soup.find_all('div',class_='item')
    for g in nu:
        #   电影序号
        num = g.find('em',class_='').get_text()
    #   print(num)
        #   电影名
        name = g.find('span',class_='title').get_text()
        name = '《'+name+'》'
         #print(name)
        #   电影英文名称
        name_english = g.find_all('span',class_='title')
        #print(name_english)
        #   由于有的没有英文名字（例如大圣娶亲就没有） 会报错 这里加个判断
        #   由于 使用 fing_all 找出为列表的
        #   中文 英文 html 标签结构一样 所以列表中包含的信息有两种
        #   通过列表切片的形式 【1】找出列表中的英文（也就是我们需要的数据）
        #  下面的结果不打印，当做能力扩展吧
        # if len(name_english)&gt;1:
        #    print(g.find_all('span',class_='title')[1].get_text())
        #   电影评分
        pingfen  =  g.find('span',class_='rating_num').get_text()
     #   print(pingfen)
        #   推荐语
        #   由于第 10 页 《网络谜踪》中 没有推荐语
       # tuijianyu = g.find('span',class_='inq').get_text()
        #print(tuijianyu)
        try:
            tuijianyu = g.find('span',class_='inq').get_text()
        except AttributeError:
            tuijianyu = &quot;=====很抱歉，这款没有推荐语=====&quot;
        #print(tuijianyu)
        #   电影的视频连接
        #    a 标签中的 href 的属性便是我们需要的
        urls = g.find('div',class_='info').find('a')['href']
        list2.append([num,name,pingfen,tuijianyu,urls])   #  将内容添加至定义的空列表中
       # print(&quot;序号: &quot;,num,&quot;电影名: &quot;,name,&quot;电影评分&quot;,pingfen,&quot;推荐语; &quot;,tuijianyu,&quot;视频链接&quot;,urls)



#  保存数据
file = openpyxl.Workbook()   #  新建一个工作薄
sheet = file.active     #  在建立工作薄后建立工作表
sheet.title = '豆瓣爬虫'   #  命名
#  开始写入
sheet['A1'] = '排名 '
sheet['B1'] = '电影名 '
sheet['C1'] = '电影评分 '
sheet['D1'] = '推荐语 '
sheet['E1'] = '链接地址 '
for i in  list2:
    print(i)
    sheet.append(i)
file.save(r&quot;C:\Users\DELL\Desktop\python_wd\文本信息\豆瓣爬虫.xlsx&quot;)  #  保存


</code></pre>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://posierd.github.io/tag/oYN426Mph/" class="tag">
                    Python-Get
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://posierd.github.io/post/shi-yong-beautifulsoup-pa-qu-xia-chu-fang-bing-bao-cun-txt-dao-ben-di-zi-ding-yi-mu-lu-xia/">
                  <h3 class="post-title">
                    使用BeautifulSoup爬取 下厨房，并包存 txt 到本地自定义目录下
                  </h3>
                </a>
              </div>
            

            
              
                <div id="gitalk-container" data-aos="fade-in"></div>
              

              
            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad()
  </script>




  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: '19e42b5385f75be24f9c',
        clientSecret: 'bdb52c22f6310d9789a397ab02c80bc37b618bad',
        repo: 'posierd.guthub.io',
        owner: 'bverbh',
        admin: ['bverbh'],
        id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
